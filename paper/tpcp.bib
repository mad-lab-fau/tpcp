
@misc{Akiba2019,
  title = {Optuna: {{A Next-generation Hyperparameter Optimization Framework}}},
  shorttitle = {Optuna},
  author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
  year = {2019},
  month = jul,
  number = {arXiv:1907.10902},
  eprint = {1907.10902},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1907.10902},
  urldate = {2022-08-10},
  abstract = {The purpose of this study is to introduce new design-criteria for next-generation hyperparameter optimization software. The criteria we propose include (1) define-by-run API that allows users to construct the parameter search space dynamically, (2) efficient implementation of both searching and pruning strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to light-weight experiment conducted via interactive interface. In order to prove our point, we will introduce Optuna, an optimization software which is a culmination of our effort in the development of a next generation optimization software. As an optimization software designed with define-by-run principle, Optuna is particularly the first of its kind. We will present the design-techniques that became necessary in the development of the software that meets the above criteria, and demonstrate the power of our new design through experimental results and real world applications. Our software is available under the MIT license (https://github.com/pfnet/optuna/).},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning}
}

@inproceedings{Barth2013,
  title = {Subsequence Dynamic Time Warping as a Method for Robust Step Segmentation Using Gyroscope Signals of Daily Life Activities},
  booktitle = {Proceedings of the {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}}, {{EMBS}}},
  author = {Barth, Jens and Oberndorfer, Cacilia and Kugler, Patrick and Schuldhaus, Dominik and Winkler, Jurgen and Klucken, Jochen and Eskofier, Bjorn},
  year = {2013},
  month = jul,
  pages = {6744--6747},
  publisher = {{IEEE}},
  issn = {1557170X},
  doi = {10.1109/EMBC.2013.6611104},
  url = {http://ieeexplore.ieee.org/document/6611104/},
  urldate = {2018-03-05},
  abstract = {The segmentation of gait signals into single steps is an important basis for objective gait analysis. Only a precise detection of step beginning and end enables the computation of step parameters like step height, variability and duration. A special challenge for the application is the accurateness of such an algorithm when based on signals from daily live activities. \textcopyright{} 2013 IEEE.},
  isbn = {978-1-4577-0216-7},
  pmid = {24111291}
}

@inproceedings{Paske2019,
  title = {{{PyTorch}}: {{An}} Imperative Style, High-Performance Deep Learning Library},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and {dAlch{\'e}-Buc}, F. and Fox, E. and Garnett, R.},
  year = {2019},
  volume = {32},
  publisher = {{Curran Associates, Inc.}}
}

@article{Pedregosa2011a,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  author = {Pedregosa, Fabian and Varoquaux, Gael and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, M. and Duchesnay, E.},
  year = {2011},
  journal = {Journal of Machine Learning Research},
  volume = {12},
  eprint = {1201.0490v2},
  eprinttype = {arxiv},
  pages = {2825--2830},
  issn = {15324435},
  doi = {10.1007/s13398-014-0173-7.2},
  abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algo-rithms for medium-scale supervised and unsupervised problems. This package focuses on bring-ing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependen-cies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
  archiveprefix = {arXiv},
  isbn = {9781783281930},
  pmid = {1000044560},
  keywords = {model selection,Python,supervised learning,unsupervised learning}
}

@article{Roth2021a,
  title = {Hidden {{Markov Model}} Based Stride Segmentation on Unsupervised Free-Living Gait Data in {{Parkinson}}'s Disease Patients},
  author = {Roth, Nils and K{\"u}derle, Arne and Ullrich, Martin and Gladow, Till and Marxreiter, Franz and Klucken, Jochen and Eskofier, Bjoern M. and Kluge, Felix},
  year = {2021},
  month = dec,
  journal = {Journal of NeuroEngineering and Rehabilitation},
  volume = {18},
  number = {1},
  pages = {93},
  issn = {1743-0003},
  doi = {10.1186/s12984-021-00883-7},
  url = {https://jneuroengrehab.biomedcentral.com/articles/10.1186/s12984-021-00883-7},
  urldate = {2021-12-25},
  abstract = {Background:\hspace{0.6em} To objectively assess a patient's gait, a robust identification of stride borders is one of the first steps in inertial sensor-based mobile gait analysis pipelines. While many different methods for stride segmentation have been presented in the literature, an out-of-lab evaluation of respective algorithms on free-living gait is still missing. Method:\hspace{0.6em} To address this issue, we present a comprehensive free-living evaluation dataset, including 146.574 semiautomatic labeled strides of 28 Parkinson's Disease patients. This dataset was used to evaluate the segmentation performance of a new Hidden Markov Model (HMM) based stride segmentation approach compared to an available dynamic time warping (DTW) based method. Results:\hspace{0.6em} The proposed HMM achieved a mean F1-score of 92.1\% and outperformed the DTW approach significantly. Further analysis revealed a dependency of segmentation performance to the number of strides within respective walking bouts. Shorter bouts ({$<\mkern1mu$} 30 strides) resulted in worse performance, which could be related to more heterogeneous gait and an increased diversity of different stride types in short free-living walking bouts. In contrast, the HMM reached F1-scores of more than 96.2\% for longer bouts ({$>\mkern1mu$} 50 strides). Furthermore, we showed that an HMM, which was trained on at-lab data only, could be transferred to a free-living context with a negligible decrease in performance. Conclusion:\hspace{0.6em} The generalizability of the proposed HMM is a promising feature, as fully labeled free-living training data might not be available for many applications. To the best of our knowledge, this is the first evaluation of stride segmentation performance on a large scale free-living dataset. Our proposed HMM-based approach was able to address the increased complexity of free-living gait data, and thus will help to enable a robust assessment of stride parameters in future free-living gait analysis applications.},
  langid = {english}
}

@article{Schreiber2017,
  title = {Pomegranate: {{Fast}} and Flexible Probabilistic Modeling in Python},
  author = {Schreiber, Jacob},
  year = {2017},
  month = jan,
  journal = {Journal of Machine Learning Research},
  volume = {18},
  number = {1},
  pages = {5992--5997},
  publisher = {{JMLR.org}},
  issn = {1532-4435},
  abstract = {We present pomegranate, an open source machine learning package for probabilistic modeling in Python. Probabilistic modeling encompasses a wide range of methods that explicitly describe uncertainty using probability distributions. Three widely used probabilistic models implemented in pomegranate are general mixture models, hidden Markov models, and Bayesian networks. A primary focus of pomegranate is to abstract away the complexities of training models from their definition. This allows users to focus on specifying the correct model for their application instead of being limited by their understanding of the underlying algorithms. An aspect of this focus involves the collection of additive sufficient statistics from data sets as a strategy for training models. This approach trivially enables many useful learning strategies, such as out-of-core learning, minibatch learning, and semi-supervised learning, without requiring the user to consider how to partition data or modify the algorithms to handle these tasks themselves. pomegranate is written in Cython to speed up calculations and releases the global interpreter lock to allow for built-in multithreaded parallelism, making it competitive with\textendash or outperform\textendash other implementations of similar algorithms. This paper presents an overview of the design choices in pomegranate, and how they have enabled complex features to be supported by simple code. The code is available at https://github.com/jmschrei/pomegranate.},
  issue_date = {January 2017},
  keywords = {big data,cython,machine learning,probabilistic modeling,python}
}

@misc{tensorflow2015-whitepaper,
  title = {{{TensorFlow}}: {{Large-scale}} Machine Learning on Heterogeneous Systems},
  author = {Abadi, Mart{\'i}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Jozefowicz, Rafal and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Man{\'e}, Dandelion and Monga, Rajat and Moore, Sherry and Murray, Derek and Olah, Chris and Schuster, Mike and Shlens, Jonathon and Steiner, Benoit and Sutskever, Ilya and Talwar, Kunal and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Vi{\'e}gas, Fernanda and Vinyals, Oriol and Warden, Pete and Wattenberg, Martin and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  year = {2015},
  url = {https://www.tensorflow.org/}
}


